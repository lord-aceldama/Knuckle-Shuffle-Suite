#!/usr/bin/env python

#-- Making Pylint behave
# pylint: disable = old-style-class
# pylint: disable = trailing-whitespace
# pylint: disable = line-too-long
# pylint: disable = bad-whitespace

""" Knuckle Shuffle
    
    author: aceldama.v1.0 at gmail
    
    Licensed under the GNU General Public License Version 2 (GNU GPL v2), 
        available at: http://www.gnu.org/licenses/gpl-2.0.txt
    
    (C) 2015 David A Swanepoel

    -----------------

    TODO:
    so many things...
"""

#-- Dependencies
#import math


#-- Global Constants
CHARSET = sorted("abcdef")


#-- Abacus class
class Abacus():
    """ THE THEORY:      The Abacus class is designed to break a large keyspace into smaller
        chunks.   When you consider the traditional incremental brute-force algoritm,   it's
        clear  to see that keys starting with larger characters render incremental  searches
        inefficient.
        
        FOR EXAMPLE:  Consider the keyspace [0-9a-f] when the 4-character key is "dacb",  it
        will scan permutations in keyspace as  [0123------------],  [1234, 2345, 3456, 4567,
        5678, 6789, 789a, 89ab, 9abc]  and  [----------abcd--] which means that the key will
        be discovered in under 2'176 keys. (11*4^4 - 10*4^3)  If the traditional incremental
        search  was  used  however,  56'011 of 65'536  keys  would  need to be tested before
        reaching the correct key.   (NOTE: Do check my math here  -  I might not be entirely
        correct, although the logic is sound.)
        
        PITFALLS:   Of course this method is not fool-proof.  If we consider the keyspace we
        used in the example and  "fed0"  was the key,   the entire keyspace would need to be
        scanned (as if "ffff" were the key used in an incremental search).   When you take a
        normal random distribution like a key generated by router manufacturers, *cough* for
        educational purposes only *cough* it can be seen  by looking at the curve on a graph
        that having both the 1st and last chars  in the keyspace is highly unlikely.     The 
        following  curve was generated by calculating  the distance between the max and  min 
        characters of a random 5 character hex key over  10'000'000  iterations  (ie. dacfb: 
        f - a = 5 etc.):
        
                                         Montecarlo Generated Graph:
        
                        0.24|                      *  *
                        0.22|                      *  *
                        0.20|                   *  *  *  *
                        0.18|                   *  *  *  *
                        0.16|                   *  *  *  *
                        0.14|                   *  *  *  *
                        0.13|                   *  *  *  *
                        0.12|                *  *  *  *  *  *
                        0.10|                *  *  *  *  *  *
                        0.08|                *  *  *  *  *  *
                        0.06|                *  *  *  *  *  *
                        0.04|             *  *  *  *  *  *  *  *
                        0.02|       *  *  *  *  *  *  *  *  *  *  *  *
                        0.00+-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
                              0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f
        
        That being said,  there's always a chance that the full  65'536  keys may need to be
        checked when brute-forcing a 4-digit hex key.
    """
    
    #-- Constants
    #[None]
    
    
    #-- Global Vars
    _charset = None     # [str] character set to be broken up and scanned
    _checked = None     # [dict([chr]:[set])] keeps track of which chars were scanned together.
    _indexes = None     # 
    _abacus  = None     # 
    
    
    #-- Special class methods
    def __init__(self, charset, token=None, token_length=None):
        """ Initializes the class. Requires a valid charset and also either
            a valid token or valid token length.
            
            VARIABLES: 
                charset:        [str] of length 1 or greater
                
                token:          [str] consisting of unique characters. If chars
                                are repeated, the correct indexes cannot be 
                                deduced.
                
                token_length:   [int] of value greater than 0
        """
        #-- Primary Assertions
        assert((type(charset) is str) and (len(charset) > 0)),      "ERR: Bad charset."
        assert(((type(token) is str) and (len(token) > 0)) or
               ((token is None) and (type(token_length) is int) and
                (len(token) == len(set(sorted(token)))))),          "ERR: Bad token/token_length."
        
        #-- Initialization
        self._charset = sorted(set(charset))
        self._checked = {char : set([]) for char in self._charset}


    def __str__(self):
        """ Returns the current token string. DOES NOT include a newline character and
            DOES NOT calculate the next token automatically. See: Abacus.print_token()
        """
        token = ""
        for idx in self._indexes:
            token += self._charset[idx]
        return token
    
    
    #-- Private methods
    def _fromindexes(self, indexes):
        """ Docstring.
        """
        offsets = [] + self._abacus
        for idx in range(1, len(indexes)):
            offsets += [0 for _ in range(1, indexes[idx] - indexes[idx - 1])]
        
        return  [1] + offsets + [1]
    
    
    def _fromstrtoken(self, token):
        """ Returns the abacus from the given token string.
        """
        offsets = [] + self._charset[0]
        
        return offsets + sorted(token)
    
    
    #-- Public methods
    def str_token(self):
        """ Returns the current token string """
        return str(self)
    
    
    def _shift(self):
        """ Docstring.
        """
        offset = 0
        shifts = []
        while offset + self._indexes[-1] < len(self._charset):
            subset = ""
            for nchr in self._indexes:
                subset += self._charset[offset + nchr]
            shifts += [subset]
            offset += 1
        
        return shifts
    
    
    def inc(self):
        """ Calculates the next token. """
        return self._indexes[0] #-- To Do
    
    
    def print_token(self):
        """ Returns the current token and calculates the next. Includes the 
            newline charcter in the returned string.
        """
        token = str(self) + "\n"
        self.inc()
        return token


#print gen_subsets(CHARSET, 4)
